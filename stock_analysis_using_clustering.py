# -*- coding: utf-8 -*-
"""Stock-Analysis-using-Clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DNrXJ9dSbipi8-B1D0OCY9OllHEH11uM
"""

import pandas as pd

# Load the stock data from CSV file
file_path = '/content/filtered_file1.xlsx'  # Update this path
df = pd.read_excel(file_path)

# Display the first few rows of the dataframe
df.head()

from sklearn.preprocessing import StandardScaler

# Fill missing values with the mean of each column
#df.fillna(df.mean(), inplace=True)

# Normalize the features
scaler = StandardScaler()
features = df.drop(columns=['S.No.','Name','Mar Cap Rs.Cr. ','Face value Rs.','Div Yld %','Debt Rs.Cr.','Prom. Hold. %','FCF Prev Ann Rs.Cr.','CMP Rs.'])  # Exclude the 'Name' column for clustering
# features = df.drop(columns=['Name'])
# features = df.drop(columns=['Mar Cap Rs.Cr. '])
# features = df.drop(columns=['Face value Rs.'])
# features = df.drop(columns=['Div Yld %'])
# features = df.drop(columns=['Debt Rs.Cr.'])
# features = df.drop(columns=['Prom. Hold. %'])
# features = df.drop(columns=['FCF Prev Ann Rs.Cr.'])
scaled_features = scaler.fit_transform(features)

# Convert back to DataFrame
scaled_df = pd.DataFrame(scaled_features, columns=features.columns)

scaled_df

from sklearn.cluster import KMeans

# Set the number of clusters
num_clusters = 9  # You can choose the number of clusters based on your requirement

# Apply K-Means clustering
kmeans = KMeans(n_clusters=num_clusters, random_state=0)
kmeans.fit(scaled_df)

# Add cluster labels to the original dataframe
df['Cluster'] = kmeans.labels_

# Print stock names in each cluster
for i in range(num_clusters):
    cluster_stocks = df[df['Cluster'] == i]['Name']
    print(f"Cluster {i}: =================================================>>")
    for stock in cluster_stocks:
        print(stock)



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# Reduce dimensions using PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(scaled_features)
df['PCA1'] = pca_result[:, 0]
df['PCA2'] = pca_result[:, 1]

# Alternative: Reduce dimensions using t-SNE
# tsne = TSNE(n_components=2, random_state=0)
# tsne_result = tsne.fit_transform(scaled_features)
# df['tSNE1'] = tsne_result[:, 0]
# df['tSNE2'] = tsne_result[:, 1]

# Plot the clusters using PCA
plt.figure(figsize=(12, 8))
sns.scatterplot(
    x='PCA1', y='PCA2',
    hue='Cluster',
    palette=sns.color_palette('hsv', num_clusters),
    data=df,
    legend='full',
    alpha=0.7
)
plt.title('Clusters of Stocks (PCA)')
plt.show()

# Alternative: Plot the clusters using t-SNE
# plt.figure(figsize=(12, 8))
# sns.scatterplot(
#     x='tSNE1', y='tSNE2',
#     hue='Cluster',
#     palette=sns.color_palette('hsv', num_clusters),
#     data=df,
#     legend='full',
#     alpha=0.7
# )
# plt.title('Clusters of Stocks (t-SNE)')
# plt.show()

tsne = TSNE(n_components=2, random_state=0)
tsne_result = tsne.fit_transform(scaled_features)
df['tSNE1'] = tsne_result[:, 0]
df['tSNE2'] = tsne_result[:, 1]

plt.figure(figsize=(12, 8))
sns.scatterplot(
    x='tSNE1', y='tSNE2',
    hue='Cluster',
    palette=sns.color_palette('hsv', num_clusters),
    data=df,
    legend='full',
    alpha=0.7
)
plt.title('Clusters of Stocks (t-SNE)')
plt.show()







